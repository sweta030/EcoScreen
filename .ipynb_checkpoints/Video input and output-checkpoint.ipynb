{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a20ba-d437-407b-bc2c-211f7d839d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST WITH IMAGE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff2119-297c-42bb-8471-8698f96820b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def draw_road_polygon_on_image(img_path, output_path):\n",
    "    display_size = (800, 600)\n",
    "    \n",
    "    # Read the image\n",
    "    image = cv2.imread(img_path)\n",
    "    \n",
    "    # Load the models\n",
    "    model_human = YOLO(\"best (human).pt\")\n",
    "    model_screen = YOLO(\"best (screen).pt\")\n",
    "    \n",
    "    # Perform prediction using the models\n",
    "    r = model_human.predict(img_path)\n",
    "    l = model_screen.predict(img_path)\n",
    "    \n",
    "    # Draw polygons for model_screen (on screen and off screen)\n",
    "    screen_polygons = []\n",
    "    off_screen_polygons = []\n",
    "    for mask_points in l[0].masks.xy:\n",
    "        polygon_points = np.array(mask_points, np.int32)\n",
    "        polygon_points = polygon_points.reshape((-1, 1, 2))\n",
    "        if 'on' in l[0].names:\n",
    "            screen_polygons.append(polygon_points)\n",
    "        else:\n",
    "            off_screen_polygons.append(polygon_points)\n",
    "    \n",
    "    # Draw blue mask for off screen\n",
    "    for off_screen_polygon in off_screen_polygons:\n",
    "        cv2.fillPoly(image, [off_screen_polygon], color=(255, 0, 0))\n",
    "    \n",
    "    # Draw polygons for model_human\n",
    "    human_polygons = []\n",
    "    for mask_points in r[0].masks.xy:\n",
    "        polygon_points = np.array(mask_points, np.int32)\n",
    "        polygon_points = polygon_points.reshape((-1, 1, 2))\n",
    "        human_polygons.append(polygon_points)\n",
    "    \n",
    "    # Process human polygons and screen polygons\n",
    "    for human_polygon in human_polygons:\n",
    "        min_dist = float('inf')\n",
    "        closest_human_point = None\n",
    "        closest_screen_point = None\n",
    "        closest_screen_polygon = None\n",
    "        \n",
    "        # Find the nearest screen polygon\n",
    "        for screen_polygon in screen_polygons:\n",
    "            for human_point in human_polygon:\n",
    "                for screen_point in screen_polygon:\n",
    "                    dist = distance.euclidean(human_point[0], screen_point[0])\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        closest_human_point = human_point[0]\n",
    "                        closest_screen_point = screen_point[0]\n",
    "                        closest_screen_polygon = screen_polygon\n",
    "        \n",
    "        # Draw the line and masks if a valid closest point is found\n",
    "        if closest_human_point is not None and closest_screen_point is not None:\n",
    "            cv2.line(image, tuple(closest_human_point), tuple(closest_screen_point), color=(255, 0, 0), thickness=5)\n",
    "            \n",
    "            # Display the Euclidean distance\n",
    "            midpoint = ((closest_human_point[0] + closest_screen_point[0]) // 2,\n",
    "                        (closest_human_point[1] + closest_screen_point[1]) // 2)\n",
    "            cv2.putText(image, f\"{min_dist:.2f}\", midpoint, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "            \n",
    "            # Draw the human mask based on the distance\n",
    "            human_mask_color = (0, 0, 255) if min_dist < 400 else (0, 255, 255)\n",
    "            cv2.fillPoly(image, [human_polygon], color=human_mask_color)\n",
    "        \n",
    "        # Mark screen polygons\n",
    "        if closest_screen_polygon is not None:\n",
    "            # Mark the screen polygon green if within range, violet otherwise\n",
    "            screen_color = (0, 255, 0) if min_dist < 400 else (238, 130, 238)\n",
    "            cv2.fillPoly(image, [closest_screen_polygon], color=screen_color)\n",
    "\n",
    "    # Resize the image for display\n",
    "    resized_image = cv2.resize(image, display_size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Save the image\n",
    "    cv2.imwrite(output_path, resized_image)\n",
    "\n",
    "# Example usage\n",
    "draw_road_polygon_on_image('3.jpg', '3_5.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360a2124-f82c-4400-96a7-0d2d25b3bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST WITH VIDEO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aedebe-8529-443e-8249-08c31d3b6793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def process_frame(frame, model_human, model_screen):\n",
    "    display_size = (800, 600)\n",
    "    \n",
    "    # Perform prediction using the models\n",
    "    r = model_human.predict(frame)\n",
    "    l = model_screen.predict(frame)\n",
    "    \n",
    "    # Draw polygons for model_screen (on screen and off screen)\n",
    "    screen_polygons = []\n",
    "    off_screen_polygons = []\n",
    "    for mask_points in l[0].masks.xy:\n",
    "        polygon_points = np.array(mask_points, np.int32)\n",
    "        polygon_points = polygon_points.reshape((-1, 1, 2))\n",
    "        if 'on' in l[0].names:\n",
    "            screen_polygons.append(polygon_points)\n",
    "        else:\n",
    "            off_screen_polygons.append(polygon_points)\n",
    "    \n",
    "    # Draw blue mask for off screen\n",
    "    for off_screen_polygon in off_screen_polygons:\n",
    "        cv2.fillPoly(frame, [off_screen_polygon], color=(255, 0, 0))\n",
    "    \n",
    "    # Draw polygons for model_human\n",
    "    human_polygons = []\n",
    "    for mask_points in r[0].masks.xy:\n",
    "        polygon_points = np.array(mask_points, np.int32)\n",
    "        polygon_points = polygon_points.reshape((-1, 1, 2))\n",
    "        human_polygons.append(polygon_points)\n",
    "    \n",
    "    # Process human polygons and screen polygons\n",
    "    for human_polygon in human_polygons:\n",
    "        min_dist = float('inf')\n",
    "        closest_human_point = None\n",
    "        closest_screen_point = None\n",
    "        closest_screen_polygon = None\n",
    "        \n",
    "        # Find the nearest screen polygon\n",
    "        for screen_polygon in screen_polygons:\n",
    "            for human_point in human_polygon:\n",
    "                for screen_point in screen_polygon:\n",
    "                    dist = distance.euclidean(human_point[0], screen_point[0])\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        closest_human_point = human_point[0]\n",
    "                        closest_screen_point = screen_point[0]\n",
    "                        closest_screen_polygon = screen_polygon\n",
    "        \n",
    "        # Draw the line and masks if a valid closest point is found\n",
    "        if closest_human_point is not None and closest_screen_point is not None:\n",
    "            cv2.line(frame, tuple(closest_human_point), tuple(closest_screen_point), color=(255, 0, 0), thickness=5)\n",
    "            \n",
    "            # Display the Euclidean distance\n",
    "            midpoint = ((closest_human_point[0] + closest_screen_point[0]) // 2,\n",
    "                        (closest_human_point[1] + closest_screen_point[1]) // 2)\n",
    "            cv2.putText(frame, f\"{min_dist:.2f}\", midpoint, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "            \n",
    "            # Draw the human mask based on the distance\n",
    "            human_mask_color = (0, 0, 255) if min_dist < 400 else (0, 255, 255)\n",
    "            cv2.fillPoly(frame, [human_polygon], color=human_mask_color)\n",
    "        \n",
    "        # Mark screen polygons\n",
    "        if closest_screen_polygon is not None:\n",
    "            # Mark the screen polygon green if within range, violet otherwise\n",
    "            screen_color = (0, 255, 0) if min_dist < 400 else (238, 130, 238)\n",
    "            cv2.fillPoly(frame, [closest_screen_polygon], color=screen_color)\n",
    "    \n",
    "    # Resize the image for display\n",
    "    resized_frame = cv2.resize(frame, display_size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return resized_frame\n",
    "\n",
    "def process_video(input_path, output_path):\n",
    "    # Open video capture\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    # Get the codec information and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec for .avi files\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Load the models\n",
    "    model_human = YOLO(\"best (human).pt\")\n",
    "    model_screen = YOLO(\"best (screen).pt\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Process the frame\n",
    "        processed_frame = process_frame(frame, model_human, model_screen)\n",
    "        \n",
    "        # Write the frame to the output video\n",
    "        out.write(processed_frame)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "process_video('input_video.mp4', 'output_video.avi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06795e68-b838-4cdd-a0ab-832ea238d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADIO INTEGRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b2408-ac8f-4e8a-967b-453666059ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from scipy.spatial import distance\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def process_frame(frame, model_human, model_screen):\n",
    "    display_size = (800, 600)\n",
    "    \n",
    "    # Perform prediction using the models\n",
    "    r = model_human.predict(frame)\n",
    "    l = model_screen.predict(frame)\n",
    "    \n",
    "    # Draw polygons for model_screen\n",
    "    screen_polygons = []\n",
    "    for mask_points in l[0].masks.xy:\n",
    "        polygon_points = np.array(mask_points, np.int32)\n",
    "        polygon_points = polygon_points.reshape((-1, 1, 2))\n",
    "        screen_polygons.append(polygon_points)\n",
    "    \n",
    "    # Draw polygons for model_human\n",
    "    human_polygons = []\n",
    "    for mask_points in r[0].masks.xy:\n",
    "        polygon_points = np.array(mask_points, np.int32)\n",
    "        polygon_points = polygon_points.reshape((-1, 1, 2))\n",
    "        human_polygons.append(polygon_points)\n",
    "    \n",
    "    # Process human polygons and screen polygons\n",
    "    for human_polygon in human_polygons:\n",
    "        min_dist = float('inf')\n",
    "        closest_human_point = None\n",
    "        closest_screen_point = None\n",
    "        closest_screen_polygon = None\n",
    "        \n",
    "        # Find the nearest screen polygon\n",
    "        for screen_polygon in screen_polygons:\n",
    "            for human_point in human_polygon:\n",
    "                for screen_point in screen_polygon:\n",
    "                    dist = distance.euclidean(human_point[0], screen_point[0])\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        closest_human_point = human_point[0]\n",
    "                        closest_screen_point = screen_point[0]\n",
    "                        closest_screen_polygon = screen_polygon\n",
    "        \n",
    "        # Draw the line and masks if a valid closest point is found\n",
    "        if closest_human_point is not None and closest_screen_point is not None:\n",
    "            cv2.line(frame, tuple(closest_human_point), tuple(closest_screen_point), color=(255, 0, 0), thickness=5)\n",
    "            \n",
    "            # Display the Euclidean distance\n",
    "            midpoint = ((closest_human_point[0] + closest_screen_point[0]) // 2,\n",
    "                        (closest_human_point[1] + closest_screen_point[1]) // 2)\n",
    "            cv2.putText(frame, f\"{min_dist:.2f}\", midpoint, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "            \n",
    "            # Check if the distance is greater than 444\n",
    "            if min_dist > 444 and closest_screen_polygon is not None:\n",
    "                # Draw a violet polygon around the screen\n",
    "                cv2.polylines(frame, [closest_screen_polygon], isClosed=True, color=(238, 130, 238), thickness=5)\n",
    "\n",
    "        # Mark screen polygons\n",
    "        if closest_screen_polygon is not None:\n",
    "            screen_color = (0, 255, 0) if min_dist < 400 else (238, 130, 238)\n",
    "            cv2.fillPoly(frame, [closest_screen_polygon], color=screen_color)\n",
    "\n",
    "    # Resize the image for display\n",
    "    resized_frame = cv2.resize(frame, display_size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return resized_frame\n",
    "\n",
    "def video_to_frames(video_file):\n",
    "    # Read the video file\n",
    "    cap = cv2.VideoCapture(video_file.name)\n",
    "    \n",
    "    # Load the models\n",
    "    model_human = YOLO(\"best (human).pt\")\n",
    "    model_screen = YOLO(\"best (screen).pt\")\n",
    "    \n",
    "    # Prepare the video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Create a buffer to save the video output\n",
    "    output_buffer = BytesIO()\n",
    "    out = cv2.VideoWriter(output_buffer, fourcc, fps, (width, height))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Process the frame\n",
    "        processed_frame = process_frame(frame, model_human, model_screen)\n",
    "        \n",
    "        # Write the processed frame to the output video\n",
    "        out.write(processed_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    output_buffer.seek(0)\n",
    "    return output_buffer\n",
    "\n",
    "def process_video(video_file):\n",
    "    output_buffer = video_to_frames(video_file)\n",
    "    return output_buffer\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=process_video,\n",
    "    inputs=gr.Video(type=\"file\"),\n",
    "    outputs=gr.Video(type=\"file\"),\n",
    "    title=\"YOLO Video Processing\",\n",
    "    description=\"Upload a video and get processed results with YOLO models drawing polygons and calculating distances.\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13b67f-89d0-4e50-a4b7-1331d1c2738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY TO TAKE LIVE VIDEO INPUT FROM WEB CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286000b8-f189-4593-a327-79d618809d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Load the YOLO models\n",
    "model_human = YOLO(\"best (human).pt\")\n",
    "model_screen = YOLO(\"best (screen).pt\")\n",
    "\n",
    "def process_frame(frame):\n",
    "    # Perform prediction using the models\n",
    "    r = model_human.predict(frame)\n",
    "    l = model_screen.predict(frame)\n",
    "    \n",
    "    # Draw polygons for model_screen\n",
    "    screen_polygons = []\n",
    "    for mask_points in l[0].masks.xy:\n",
    "        polygon_points = np.array(mask_points, np.int32)\n",
    "        polygon_points = polygon_points.reshape((-1, 1, 2))\n",
    "        screen_polygons.append(polygon_points)\n",
    "    \n",
    "    # Draw polygons for model_human\n",
    "    human_polygons = []\n",
    "    for mask_points in r[0].masks.xy:\n",
    "        polygon_points = np.array(mask_points, np.int32)\n",
    "        polygon_points = polygon_points.reshape((-1, 1, 2))\n",
    "        human_polygons.append(polygon_points)\n",
    "    \n",
    "    # Process human polygons and screen polygons\n",
    "    for human_polygon in human_polygons:\n",
    "        min_dist = float('inf')\n",
    "        closest_human_point = None\n",
    "        closest_screen_point = None\n",
    "        closest_screen_polygon = None\n",
    "        \n",
    "        # Find the nearest screen polygon\n",
    "        for screen_polygon in screen_polygons:\n",
    "            for human_point in human_polygon:\n",
    "                for screen_point in screen_polygon:\n",
    "                    dist = distance.euclidean(human_point[0], screen_point[0])\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        closest_human_point = human_point[0]\n",
    "                        closest_screen_point = screen_point[0]\n",
    "                        closest_screen_polygon = screen_polygon\n",
    "        \n",
    "        # Draw the line and masks if a valid closest point is found\n",
    "        if closest_human_point is not None and closest_screen_point is not None:\n",
    "            cv2.line(frame, tuple(closest_human_point), tuple(closest_screen_point), color=(255, 0, 0), thickness=5)\n",
    "            \n",
    "            # Display the Euclidean distance\n",
    "            midpoint = ((closest_human_point[0] + closest_screen_point[0]) // 2,\n",
    "                        (closest_human_point[1] + closest_screen_point[1]) // 2)\n",
    "            cv2.putText(frame, f\"{min_dist:.2f}\", midpoint, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "            \n",
    "            # Check if the distance is greater than 444\n",
    "            if min_dist > 444 and closest_screen_polygon is not None:\n",
    "                # Draw a violet polygon around the screen\n",
    "                cv2.polylines(frame, [closest_screen_polygon], isClosed=True, color=(238, 130, 238), thickness=5)\n",
    "\n",
    "        # Mark screen polygons\n",
    "        if closest_screen_polygon is not None:\n",
    "            screen_color = (0, 255, 0) if min_dist < 400 else (238, 130, 238)\n",
    "            cv2.fillPoly(frame, [closest_screen_polygon], color=screen_color)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def main():\n",
    "    # Open a connection to the webcam\n",
    "    cap = cv2.VideoCapture(0)  # 0 is the default webcam\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process the frame\n",
    "        processed_frame = process_frame(frame)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Masked Video', processed_frame)\n",
    "        \n",
    "        # Exit loop when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the webcam and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
